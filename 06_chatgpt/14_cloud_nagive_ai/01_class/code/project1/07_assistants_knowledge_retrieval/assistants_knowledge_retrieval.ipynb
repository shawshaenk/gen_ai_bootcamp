{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API - Knowledge Retrieval \n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/knowledge-retrieval\n",
    "\n",
    "https://community.openai.com/t/new-assistants-api-a-potential-replacement-for-low-level-rag-style-content-generation/475677 \n",
    "\n",
    "Watch:\n",
    "\n",
    "https://youtu.be/5rcjGjgJNQc?t=600&si=d9OtX0nMi2Rv0fQV \n",
    "\n",
    "References:\n",
    "\n",
    "https://community.openai.com/t/assistants-api-retrieval-pricing-how-much-does-this-cost/485188/8\n",
    "\n",
    "https://medium.com/madhukarkumar/what-does-openais-announcement-mean-for-retrieval-augmented-generation-rag-and-vector-only-54bfc34cba2c\n",
    "\n",
    "https://www.youtube.com/watch?v=ClfyQNkTeUc\n",
    "\n",
    "https://www.pinecone.io/learn/assistants-api-canopy/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](ret.jpg \"Assistants\")\n",
    "\n",
    "![Alt text](objects.jpeg \"Assistants_Objects\")\n",
    "\n",
    "https://cobusgreyling.medium.com/openai-assistant-with-retriever-tool-08e9158ca900 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Retrieval\n",
    "\n",
    "Retrieval augments the Assistant with knowledge from outside its model, such as proprietary product information or documents provided by your users. Once a file is uploaded and passed to the Assistant, OpenAI will automatically chunk your documents, index and store the embeddings, and implement vector search to retrieve relevant content to answer user queries.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/knowledge-retrieval \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "The model then decides when to retrieve content based on the user Messages. The Assistants API automatically chooses between two retrieval techniques:\n",
    "\n",
    "1. it either passes the file content in the prompt for short documents, or\n",
    "2. performs a vector search for longer documents\n",
    "\n",
    "Retrieval currently optimizes for quality by adding all relevant content to the context of model calls. We plan to introduce other retrieval strategies to enable developers to choose a different tradeoff between retrieval quality and model usage cost.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/how-it-works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Upload the file and Create an Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store caled \"Sir Zia BioGraphy\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"Sir Zia Biography\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"zia_profile.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant: Assistant = client.beta.assistants.create(\n",
    "  name=\"Student Support Assistant\",\n",
    "  instructions=\"You are a student support chatbot. Use your knowledge base to best respond to student queries about Zia U. Khan.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_GRbd9ogrErAhIO8OrXzR6772', created_at=1718204571, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread  = client.beta.threads.create()\n",
    "\n",
    "print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add a Message to a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"When and which city Zia U. Khan was born?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Pakistani. The user is the student of PIAIC.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check the Run status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_PK32oDm9Ly2CPlEKA9ivlBXH', assistant_id='asst_8qgXeWGG8UX6Hh6xleZwHmtW', cancelled_at=None, completed_at=1718204579, created_at=1718204576, expires_at=None, failed_at=None, incomplete_details=None, instructions='Please address the user as Pakistani. The user is the student of PIAIC.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, response_format='auto', started_at=1718204576, status='completed', thread_id='thread_GRbd9ogrErAhIO8OrXzR6772', tool_choice='auto', tools=[FileSearchTool(type='file_search')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=59, prompt_tokens=3799, total_tokens=3858), temperature=1.0, top_p=1.0, tool_resources={}, parallel_tool_calls=True)\n"
     ]
    }
   ],
   "source": [
    "run: Run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "\n",
    "print(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Display the Assistant's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: When and which city Zia U. Khan was born?\n",
      "assistant: Zia U. Khan was born in Sialkot in 1961 in an army garrison. This information can be found in the \"zia_profile.pdf\" document .\n"
     ]
    }
   ],
   "source": [
    "# from openai.resources.beta.threads.messages.messages import SyncCursorPage \n",
    "\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "for m in reversed(messages.data):\n",
    "  print(m.role + \": \" + m.content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Zia U. Khan was born in Sialkot in 1961 in an army garrison .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Pakistani. The user is the student of PIAIC.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
